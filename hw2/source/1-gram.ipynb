{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import xml.etree.ElementTree as ET\n",
    "from collections import Counter\n",
    "\n",
    "# filename\n",
    "DATA_DIR = '../data'\n",
    "TRAIN_ANS_FILE = os.path.join(DATA_DIR, 'ans_train.csv')\n",
    "QUERY_TRAIN_FILE = os.path.join(DATA_DIR, 'query-train.xml')\n",
    "QUERY_TEST_FILE = os.path.join(DATA_DIR, 'query-test.xml')\n",
    "FILE_LIST = os.path.join(DATA_DIR, 'file-list')\n",
    "INV_FILE = os.path.join(DATA_DIR, 'inverted-file')\n",
    "VOCAB_FILE = os.path.join(DATA_DIR, 'vocab.all')\n",
    "OUTPUT_FILE = 'output.csv'\n",
    "\n",
    "# building maps\n",
    "docname2id = dict()\n",
    "with open(FILE_LIST, 'r') as f:\n",
    "    for idx, line in enumerate(f):\n",
    "        docname2id[line.strip()] = idx\n",
    "id2docname = {y:x for x, y in docname2id.items()}\n",
    "\n",
    "word2id = dict()\n",
    "with open(VOCAB_FILE, 'r') as f:\n",
    "    f.readline()\n",
    "    for idx, line in enumerate(f, 1):\n",
    "        word2id[line.strip()] = idx\n",
    "\n",
    "word_freq = dict()\n",
    "gram_freq = dict()\n",
    "gram2id = dict()\n",
    "with open(INV_FILE, 'r') as f:\n",
    "    idx = 0\n",
    "    while True:\n",
    "        line = f.readline().strip()\n",
    "        if not line:\n",
    "            break\n",
    "        id_1, id_2, doc_count = [int(i) for i in line.split(' ')]\n",
    "        doc_records = defaultdict(int)\n",
    "        for i in range(doc_count):\n",
    "            doc_id, freq = [int(i) for i in f.readline().strip().split(' ')]\n",
    "            doc_records[doc_id] = freq\n",
    "        if id_2 == -1:\n",
    "            word_freq[(id_1)] = doc_records\n",
    "        gram_freq[(id_1, id_2)] = doc_records\n",
    "        gram2id[(id_1, id_2)] = idx\n",
    "        idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc2len = defaultdict(int)\n",
    "for word_id, records in word_freq.items():\n",
    "    for doc_id, freq in records.items():\n",
    "        doc2len[doc_id] += freq\n",
    "avdl = sum([length for _, length in doc2len.items()]) / len(doc2len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = ET.ElementTree(file=QUERY_TRAIN_FILE)\n",
    "root = tree.getroot()\n",
    "\n",
    "query_num = len(root)\n",
    "word_num = len(word2id) + 1\n",
    "doc_num = len(docname2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_candidates_weight(k_1=1.5, b=0.75):\n",
    "    weight = np.zeros((doc_num, word_num))\n",
    "    for word_id, records in word_freq.items():\n",
    "        IDF = np.log((doc_num - len(records) + 0.5) / (len(records) + 0.5))\n",
    "        for doc_id, freq in records.items():\n",
    "            TF = (k_1 + 1) * freq / (freq + k_1 * (1 - b + b * doc2len[doc_id] / avdl))\n",
    "            weight[doc_id, word_id] = TF * IDF\n",
    "    return weight\n",
    "\n",
    "def generate_queries_weight(ka=100):\n",
    "    queries = np.zeros((query_num, word_num))\n",
    "    for query_id, child in enumerate(root):\n",
    "        query = list(''.join(child[4].text.strip('\\n。 ').split('、')))\n",
    "        for word, freq in Counter(query).items():\n",
    "            TF = (ka + 1) * freq / (freq + ka)\n",
    "            queries[query_id, word2id[word]] = TF\n",
    "    return queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MAP(top100):\n",
    "    AP = []\n",
    "    with open(TRAIN_ANS_FILE, 'r') as f:\n",
    "        f.readline()\n",
    "        for line, rank in zip(f, top100):\n",
    "            idx, answer = line.strip().split(',')\n",
    "            answer = set(answer.split())\n",
    "            rank = [(id2docname[i].split('/')[-1].lower()) for i in rank]\n",
    "            hit = 0\n",
    "            P = []\n",
    "            for rank_i, rank in enumerate(rank, 1):\n",
    "                if rank in answer:\n",
    "                    hit += 1\n",
    "                    P.append(hit / rank_i)\n",
    "            AP.append(sum(P) / len(P))\n",
    "    return sum(AP) / len(AP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k_1: 1.00, ka: 0.00, MPA: 0.74668724\n",
      "k_1: 1.00, ka: 5.00, MPA: 0.76675177\n",
      "k_1: 1.00, ka: 10.00, MPA: 0.76820874\n",
      "k_1: 1.00, ka: 50.00, MPA: 0.76123452\n",
      "k_1: 1.00, ka: 100.00, MPA: 0.76131936\n",
      "k_1: 1.00, ka: 300.00, MPA: 0.74796550\n",
      "k_1: 1.00, ka: 500.00, MPA: 0.74808396\n",
      "k_1: 1.00, ka: 1000.00, MPA: 0.74827093\n",
      "k_1: 1.20, ka: 0.00, MPA: 0.74890794\n",
      "k_1: 1.20, ka: 5.00, MPA: 0.77350216\n",
      "k_1: 1.20, ka: 10.00, MPA: 0.76841307\n",
      "k_1: 1.20, ka: 50.00, MPA: 0.74993208\n",
      "k_1: 1.20, ka: 100.00, MPA: 0.74674577\n",
      "k_1: 1.20, ka: 300.00, MPA: 0.74795278\n",
      "k_1: 1.20, ka: 500.00, MPA: 0.74672377\n",
      "k_1: 1.20, ka: 1000.00, MPA: 0.74683806\n",
      "k_1: 1.40, ka: 0.00, MPA: 0.74795993\n",
      "k_1: 1.40, ka: 5.00, MPA: 0.77550306\n",
      "k_1: 1.40, ka: 10.00, MPA: 0.77280180\n",
      "k_1: 1.40, ka: 50.00, MPA: 0.75247331\n",
      "k_1: 1.40, ka: 100.00, MPA: 0.75039241\n",
      "k_1: 1.40, ka: 300.00, MPA: 0.74818632\n",
      "k_1: 1.40, ka: 500.00, MPA: 0.74390922\n",
      "k_1: 1.40, ka: 1000.00, MPA: 0.74185115\n",
      "k_1: 1.60, ka: 0.00, MPA: 0.74507317\n",
      "k_1: 1.60, ka: 5.00, MPA: 0.77809484\n",
      "k_1: 1.60, ka: 10.00, MPA: 0.76718137\n",
      "k_1: 1.60, ka: 50.00, MPA: 0.74908762\n",
      "k_1: 1.60, ka: 100.00, MPA: 0.74365021\n",
      "k_1: 1.60, ka: 300.00, MPA: 0.74146141\n",
      "k_1: 1.60, ka: 500.00, MPA: 0.74115887\n",
      "k_1: 1.60, ka: 1000.00, MPA: 0.73987814\n",
      "k_1: 1.80, ka: 0.00, MPA: 0.74642615\n",
      "k_1: 1.80, ka: 5.00, MPA: 0.77412170\n",
      "k_1: 1.80, ka: 10.00, MPA: 0.76350507\n",
      "k_1: 1.80, ka: 50.00, MPA: 0.74346092\n",
      "k_1: 1.80, ka: 100.00, MPA: 0.73900959\n",
      "k_1: 1.80, ka: 300.00, MPA: 0.73801390\n",
      "k_1: 1.80, ka: 500.00, MPA: 0.73674736\n",
      "k_1: 1.80, ka: 1000.00, MPA: 0.73518530\n",
      "k_1: 2.00, ka: 0.00, MPA: 0.74436845\n",
      "k_1: 2.00, ka: 5.00, MPA: 0.76517318\n",
      "k_1: 2.00, ka: 10.00, MPA: 0.76156937\n",
      "k_1: 2.00, ka: 50.00, MPA: 0.73737144\n",
      "k_1: 2.00, ka: 100.00, MPA: 0.73573012\n",
      "k_1: 2.00, ka: 300.00, MPA: 0.73522827\n",
      "k_1: 2.00, ka: 500.00, MPA: 0.73549959\n",
      "k_1: 2.00, ka: 1000.00, MPA: 0.73546074\n"
     ]
    }
   ],
   "source": [
    "for k_1 in [1, 1.2, 1.4, 1.6, 1.8, 2.0]:\n",
    "    for ka in [0, 5, 10, 50, 100, 300, 500, 1000]:\n",
    "        candidates = generate_candidates_weight(k_1, b=0.75)\n",
    "        queries = generate_queries_weight(ka)\n",
    "        ret = np.matmul(queries, np.transpose(candidates)).argsort(axis=1)[:, ::-1][:, :100]\n",
    "        print('k_1: %.2f, ka: %.2f, MPA: %.8f' % (k_1, ka, MAP(ret)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing Part\n",
    "tree = ET.ElementTree(file=QUERY_TEST_FILE)\n",
    "root = tree.getroot()\n",
    "query_num = len(root)\n",
    "\n",
    "candidates = generate_candidates_weight(k_1=1.6, b=0.75)\n",
    "queries = generate_queries_weight(ka=5.0)\n",
    "ret = np.matmul(queries, np.transpose(candidates)).argsort(axis=1)[:, ::-1][:, :100]\n",
    "\n",
    "with open(OUTPUT_FILE, 'w+') as f:\n",
    "    print('query_id,retrieved_docs', file=f)\n",
    "    for idx, result in enumerate(ret, 11):\n",
    "        print(str(idx).zfill(3), ' '.join([(id2docname[i].split('/')[-1].lower()) for i in result]), sep=',', file=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
